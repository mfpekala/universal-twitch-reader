{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02f2853c",
   "metadata": {},
   "source": [
    "# Notes on Problem\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05206f6f",
   "metadata": {},
   "source": [
    "## Challenge: Support many different text areas robustly\n",
    "\n",
    "Robustness is key. Not every film/game/whatever has the same number of text boxes, or in the same places, etc. Even in the same stream, textboxes may change size, be occluded, in unknown ways.\n",
    "\n",
    "It seems one of the first (and probably harder) tasks here is to make sure that we can accurately identify the different text areas, and maintain continuity of those text areas between frames."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d89eea1",
   "metadata": {},
   "source": [
    "## What does a solution even look like?\n",
    "\n",
    "### High Level Solution\n",
    "\n",
    "Robustness for games: idea of text groups. The idea is that while we are processing the data, we will naturally find \"groups\" of text that make sense. In the example of streams, this can be:\n",
    "\n",
    "- In-game chat\n",
    "- Twitch chat\n",
    "- Game information (things like \"Channeling\", health numbers, timer, kill count, etc.)\n",
    "\n",
    "During the initial processing, we will auto-detect these groups. This will probably be done by some kind of classification or clustering, using some efficient pre-trained network (maybe MobileNet?).\n",
    "\n",
    "Afterwards, we want to expose an easy to use UI which will visualize all of these groups for the user and have them be able to label them, merge them, (STRETCH) split them.\n",
    "\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "Make a pass through the data and identify the different types of text. Important notes:\n",
    "\n",
    "- Air on the side of more groups. It's a better user experience (and easier technically) for the user to combine these later or tell the system (actually these are the same thing)\n",
    "- Have a fallback group and minimal probability. In the long term I don't know exactly what the solution looks like here, but for this project we care most about nailing the main important text. Smaller things which may be outliers can be thrown in a bucket to start, and we should have a convenient way of setting some kind of floor probability for the system to designate a new bucket\n",
    "\n",
    "### Actual OCR\n",
    "\n",
    "Make a more expensive pass through the data using some SOTA OCR engine and track every change to the relevant group. Important notes:\n",
    "\n",
    "- One simple (but probably costly/wasteful) idea is just to do regular timestamps on every group. This is likely a bad idea\n",
    "- The better idea is to have the frequency of \"check-ins\" be a tunable parameter (to help support lower-end hardwares) and then at every check-in compare the text predicted for one group to what it was at the last check in, and only write data if there's a change\n",
    "\n",
    "### Aggregation\n",
    "\n",
    "Aggregate the data in a more organized way. This basically means only tracking changes and marking them nicely with timestamps.\n",
    "\n",
    "### Post-processing\n",
    "\n",
    "Now we expose everything we've done to the user and solicit them for better names of the groups, combine/split groups as they see fit. \n",
    "\n",
    "IDEA: Some kinds of characters (think dragon up, baron up, kill icon) probably don't exist in English. A stretch goal would be to note this and also expose it to the user so they can give it more readable names as they wish to do sorting and cataloging."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94dee004",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04bf2b72",
   "metadata": {},
   "source": [
    "# Implementation Goal 1: Pre-process into Text Groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72930489",
   "metadata": {},
   "source": [
    "## Attempt 1: Using [CRAFT](https://pypi.org/project/craft-text-detector/)\n",
    "\n",
    "Difficulty installing. Going to tesseract, which was recommended anyway"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0f199e1",
   "metadata": {},
   "source": [
    "## Attempt 2: Using Tesseract\n",
    "\n",
    "Was able to get a basic image to text + text box working.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- For league streams, some of the text is quite small, so the difference between .png and .jpeg actually seems significant ACTUALLY not convinced, stick with JPEG for now for speed\n",
    "- There's a fair amount of noise. I.e., there are a lot of boxes around seemingly nothing, and some of the boxes flicker in and out between streams\n",
    "- The boxes are surrounding individual words, not sentences.\n",
    "\n",
    "Next steps:\n",
    "- Explore tesseract documentation better to see if there's any built in tools that will let me detect larger boxes\n",
    "- If NOT, build something custom that's loosely based on clustering / distance between boxes.\n",
    "- Try out some of the optimizations [here](https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html)\n",
    "  - Inverting seems good\n",
    "  - Noise removal seems good\n",
    "  - Better binarization seems good"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9c74bc8",
   "metadata": {},
   "source": [
    "### Attempt 2.1: Simple Bigger Boxes\n",
    "\n",
    "As noted above, the simple extraction steps tended to give boxes around individual words. I think this is because I just wasn't using the right data from the tesseract output.\n",
    "\n",
    "Yup, I should first be looking at block_num. Then aggregating. Then worrying about par_num and creating consistent logs and the like.\n",
    "\n",
    "This is looking pretty decent! I was able to get boxes to blend together better\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "996d14db",
   "metadata": {},
   "source": [
    "### Attempt 2.2: Better Binarization\n",
    "\n",
    "It's not entirely clear what kind of binarization is going on under the hood in tessaract. As suggested in the docs, it's possible that performing our own custom binarization may improve results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8a601f2",
   "metadata": {},
   "source": [
    "# Implementation Goal Two: Segment into Classes with the Help of the User"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0a239b8",
   "metadata": {},
   "source": [
    "## Attempt 1: Clustering Using Feature Vectors from Existing Classification Net\n",
    "\n",
    "The biggest problem here is that the bounding boxes are potentially very different sizes. The first thing I'm going to try is simply resizing all images to have the same dimensions and plugging in to an existing efficient network (MobileNet perhaps) to get feature vectors and then cluster from there."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4db474a5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

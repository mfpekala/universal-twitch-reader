{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pytesseract import Output\n",
    "import pytesseract\n",
    "import cv2\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from vid2frames import convert2frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 578/578 [00:41<00:00, 14.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# First run vid2frames on the video I'll be dugging OCR on\n",
    "\n",
    "def reset_frames(input_path: str, output_folder: str):\n",
    "    if os.path.exists(output_folder):\n",
    "        os.system(f\"rm -rf {output_folder}\")\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "        os.mkdir(output_folder + \"/images\")\n",
    "    convert2frames(input_path, output_folder + \"/images\")\n",
    "\n",
    "reset_frames(\"../videos/artisanal/play_ninety.mp4\", \"../frames/play_ninety\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': [1, 2, 3, 4, 5], 'page_num': [1, 1, 1, 1, 1], 'block_num': [0, 1, 1, 1, 1], 'par_num': [0, 0, 1, 1, 1], 'line_num': [0, 0, 0, 1, 1], 'word_num': [0, 0, 0, 0, 1], 'left': [0, 85, 85, 85, 85], 'top': [0, 0, 0, 0, 0], 'width': [640, 473, 473, 473, 473], 'height': [360, 360, 360, 360, 360], 'conf': [-1, -1, -1, -1, 95], 'text': ['', '', '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "# Don't bother with the dataset and the dataloader just yet\n",
    "\n",
    "def draw_basic_result(fin: str, min_conf: float = 0.95):\n",
    "    image = cv2.imread(fin)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pytesseract.image_to_data(rgb, output_type=Output.DICT)\n",
    "    print(results)\n",
    "    \n",
    "    for i in range(0, len(results[\"text\"])):\n",
    "        # Get the box\n",
    "        x = results[\"left\"][i]\n",
    "        y = results[\"top\"][i]\n",
    "        w = results[\"width\"][i]\n",
    "        h = results[\"height\"][i]\n",
    "        \n",
    "        # Text and confidence\n",
    "        text = results[\"text\"][i]\n",
    "        conf = int(results[\"conf\"][i])\n",
    "        \n",
    "        # Draw on the image\n",
    "        if conf > min_conf:\n",
    "            text = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1.2, (0, 0, 255), 3)\n",
    "            \n",
    "    # Save it to see quality \n",
    "    cv2.imwrite(\"temp.jpg\", image)\n",
    "\n",
    "draw_basic_result(\"../frames/play_ninety/images/f_162000.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras_ocr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# keras-ocr will automatically download pretrained\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# weights for the detector and recognizer.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kino/lib/python3.11/site-packages/keras_ocr/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     detection,\n\u001b[1;32m      3\u001b[0m     recognition,\n\u001b[1;32m      4\u001b[0m     tools,\n\u001b[1;32m      5\u001b[0m     data_generation,\n\u001b[1;32m      6\u001b[0m     pipeline,\n\u001b[1;32m      7\u001b[0m     evaluation,\n\u001b[1;32m      8\u001b[0m     datasets,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.0.0\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/kino/lib/python3.11/site-packages/keras_ocr/detection.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mefficientnet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtfkeras\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mefficientnet\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Get a set of three example images\n",
    "images = [\n",
    "    keras_ocr.tools.read(url) for url in [\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/b/bd/Army_Reserves_Recruitment_Banner_MOD_45156284.jpg',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/e/e8/FseeG2QeLXo.jpg',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/b/b4/EUBanana-500x112.jpg'\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Each list of predictions in prediction_groups is a list of\n",
    "# (word, box) tuples.\n",
    "prediction_groups = pipeline.recognize(images)\n",
    "\n",
    "# Plot the predictions\n",
    "fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Result](temp.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
